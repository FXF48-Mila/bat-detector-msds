{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Complete MSDS pipeline breakdown**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Start with our imports:\n",
    "\n",
    "### The cell below contains the imports needed for `src/pipeline/pipeline.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below contains the imports needed for `src/pipeline/audio_segmentor.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below contains the imports needed for `src/cli.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# # append the path of the\n",
    "# # parent directory\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src/')\n",
    "sys.path.append('../src/models/bat_call_detector/batdetect2/')\n",
    "\n",
    "from src.cfg import get_config\n",
    "from src.pipeline import pipeline\n",
    "import bat_detect.utils.detector_utils as du\n",
    "from bat_detect.detector import models\n",
    "import bat_detect.detector.compute_features as feats\n",
    "import bat_detect.detector.post_process as pp\n",
    "import bat_detect.utils.audio_utils as au"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Write any custom methods below:\n",
    "\n",
    "### The below method is a modified version of the generate_segments() method found in `src/pipeline/audio_segmentor.py`\n",
    "\n",
    "The modifications are:\n",
    "- Needed to use soundfile to read in only desired frames from audio file, so changed the dependency of librosa in `src/pipeline/audio_segmentor.py` to soundfile.\n",
    "- The naming convention of the segments did not contain start_time. They were 0.00_(endtime) for all segments. Changed this to (starttime)_(endtime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_segments(audio_file: Path, output_dir: Path, start_time: float, duration: float):\n",
    "    \"\"\"\n",
    "    Segments audio_file into clips of duration length and saves them to output_dir.\n",
    "    start_time: seconds\n",
    "    duration: seconds\n",
    "    \"\"\"\n",
    "\n",
    "    ip_audio = sf.SoundFile(audio_file)\n",
    "\n",
    "    sampling_rate = ip_audio.samplerate\n",
    "    # Convert to sampled units\n",
    "    ip_start = int(start_time * sampling_rate)\n",
    "    ip_duration = int(duration * sampling_rate)\n",
    "    ip_end = ip_audio.frames\n",
    "\n",
    "    output_files = []\n",
    "\n",
    "    # for the length of the duration, process the audio into duration length clips\n",
    "    for sub_start in range(ip_start, ip_end, ip_duration):\n",
    "        sub_end = np.minimum(sub_start + ip_duration, ip_end)\n",
    "\n",
    "        # For file names, convert back to seconds \n",
    "        op_file = os.path.basename(audio_file.name).replace(\" \", \"_\")\n",
    "        start_seconds =  sub_start / sampling_rate\n",
    "        end_seconds =  sub_end / sampling_rate\n",
    "        op_file_en = \"__{:.2f}\".format(start_seconds) + \"_\" + \"{:.2f}\".format(end_seconds)\n",
    "        op_file = op_file[:-4] + op_file_en + \".wav\"\n",
    "        \n",
    "        op_path = os.path.join(output_dir, op_file)\n",
    "        output_files.append({\n",
    "            \"audio_file\": op_path, \n",
    "            \"offset\":  start_time + (sub_start/sampling_rate),\n",
    "        })\n",
    "        \n",
    "        if (os.path.exists(op_path) == False):\n",
    "            sub_length = sub_end - sub_start\n",
    "            ip_audio.seek(sub_start)\n",
    "            op_audio = ip_audio.read(sub_length)\n",
    "            sf.write(op_path, op_audio, sampling_rate, subtype='PCM_16')\n",
    "\n",
    "    return output_files "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Now we begin our actual dissection of the MSDS pipeline:\n",
    "\n",
    "### Let's start with the audio file that the MSDS team used for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"{Path.home()}/Documents/Research/Lab_related\"\n",
    "filename = \"20210910_030000.WAV\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below command is the command line invocation of the MSDS pipeline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command: `python src/cli.py --csv --num_processes=4 audio.wav output_dir/`\n",
    "\n",
    "- `--csv` is optional; .tsv is the default format of the output detections file\n",
    "- `--num_processes=4` is optional; default num_processes = 4\n",
    "- `audio.wav` is required; this is the input audio file\n",
    "- `output_dir/` is required; this is the directory where the detections.csv/tsv will be stored"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the above command runs the following code:\n",
    "\n",
    "- `args = parse_args()`: **Takes in the command line positional arguments**\n",
    "\n",
    "- `cfg = get_config()`: **Sets default model configuration found in `src/cfg.py`**\n",
    "\n",
    "- `cfg[\"should_csv\"] = args[\"csv\"]`\n",
    "\n",
    "- `cfg[\"output_dir\"] = Path(args[\"output_directory\"])`\n",
    "\n",
    "- `cfg[\"tmp_dir\"] = Path(args[\"tmp_directory\"])`\n",
    "\n",
    "- `cfg[\"audio_file\"] = Path(args[\"input_audio\"])`\n",
    "\n",
    "- `cfg[\"num_processes\"] = args[\"num_processes\"]`\n",
    "\n",
    "- `_ = pipeline.run(cfg)`: **Begins the pipeline by passing the model configurations, input audio, and output directory**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below cell contains hard-coded arguments for the args dictionary\n",
    "\n",
    "Note: args[\"output_directory\"] and args[\"tmp_directory\"] have default values if arguments not provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict()\n",
    "args[\"input_audio\"] = f'{filepath}/{filename}'\n",
    "args[\"output_directory\"] = f'../output_dir/'\n",
    "args[\"tmp_directory\"] = f'../output/tmp'\n",
    "args[\"csv\"] = True\n",
    "args[\"num_processes\"] = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below cell contains the cfg model parameters just as they are called in original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_expansion_factor': 1.0,\n",
       " 'start_time': 0.0,\n",
       " 'segment_duration': 30.0,\n",
       " 'models': [<models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>],\n",
       " 'should_csv': True,\n",
       " 'output_dir': PosixPath('../output_dir'),\n",
       " 'tmp_dir': PosixPath('../output/tmp'),\n",
       " 'audio_file': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV'),\n",
       " 'num_processes': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = get_config()\n",
    "cfg[\"should_csv\"] = args[\"csv\"]\n",
    "cfg[\"output_dir\"] = Path(args[\"output_directory\"])\n",
    "cfg[\"tmp_dir\"] = Path(args[\"tmp_directory\"])\n",
    "cfg[\"audio_file\"] = Path(f'{filepath}/{filename}')\n",
    "cfg[\"num_processes\"] = args[\"num_processes\"]\n",
    "cfg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When pipeline.run(cfg) is called, the following code is run:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `_prepare_output_dirs(cfg)` \n",
    "   - **Make output and temp directories if they don't already exist**\n",
    "- `segmented_file_paths = _segment_input_audio(cfg)` \n",
    "   - **Generate segments of [segment_duration] length from input_audio for model**\n",
    "- `return _apply_models(cfg, segmented_file_paths)`\n",
    "   - **Apply model on each audio segment and concatenate results into a final detections dataframe that is also saved in the output directory**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Let's skip `prepare_output_dirs(cfg)` since we already have those directories**\n",
    "\n",
    "### Below is the code contained in `_segment_input_audio(cfg)`\n",
    "\n",
    "- Here I am calling my custom `generate_segments()` function defined above\n",
    "- `pipeline.generate_segments()` can also be used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_file_paths = generate_segments(\n",
    "        audio_file = cfg['audio_file'], \n",
    "        output_dir = cfg['tmp_dir'],\n",
    "        start_time = cfg['start_time'],\n",
    "        duration   = cfg['segment_duration'],\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the relevant code for `_apply_models(cfg, segmented_file_paths)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_models(cfg, segmented_file_paths):\n",
    "    csv_names = []\n",
    "    audio_file_path = cfg['audio_file']\n",
    "    process_pool = multiprocessing.Pool(cfg['num_processes'])\n",
    "\n",
    "    for model in cfg['models']:\n",
    "\n",
    "        l_for_mapping = [{\n",
    "            'audio_seg': audio_seg, \n",
    "            'model': model,\n",
    "            'original_file_name': audio_file_path,\n",
    "            } for audio_seg in segmented_file_paths]\n",
    "\n",
    "        pred_dfs = tqdm(\n",
    "            process_pool.imap(_apply_model, l_for_mapping, chunksize=1), \n",
    "            desc=f\"Applying {model.get_name()}\",\n",
    "            total=len(l_for_mapping),\n",
    "        )\n",
    "\n",
    "        agg_df = gen_empty_df() \n",
    "        agg_df = pd.concat(pred_dfs, ignore_index=True)\n",
    "\n",
    "        csv_name = _generate_csv(agg_df, model.get_name(),\n",
    "            audio_file_path.name,\n",
    "            cfg['output_dir'],\n",
    "            cfg['should_csv']\n",
    "        )\n",
    "        csv_names.append(csv_name)\n",
    "\n",
    "    return csv_names\n",
    "\n",
    "def _apply_model(item):\n",
    "    annotations_df = item['model'].run(item['audio_seg']['audio_file'])\n",
    "    return pipeline._correct_annotation_offsets(\n",
    "        annotations_df,\n",
    "        item['original_file_name'],\n",
    "        item['audio_seg']['offset']\n",
    "    )\n",
    "\n",
    "def _generate_csv(annotation_df, model_name, audio_file_name, output_path, should_csv):\n",
    "    file_name = f\"{model_name}-{audio_file_name}\"\n",
    "    extension = \".csv\"\n",
    "    sep = \",\"\n",
    "\n",
    "    if not should_csv:\n",
    "        extension = \".txt\"\n",
    "        sep = \"\\t\"\n",
    "        annotation_df = convert_df_ravenpro(annotation_df)\n",
    "\n",
    "    csv_path = output_path / f\"{file_name}{extension}\"\n",
    "    annotation_df.to_csv(csv_path, sep=sep, index=False)\n",
    "    return csv_path\n",
    "\n",
    "def gen_empty_df():\n",
    "    \"\"\"\n",
    "    Generates an empty dataframe with the correct columns for the output csv\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\n",
    "            \"start_time\": [],\n",
    "            \"end_time\": [],\n",
    "            \"low_freq\": [],\n",
    "            \"high_freq\": [],\n",
    "            \"detection_confidence\":[],\n",
    "            \"event\": [],\n",
    "        })\n",
    "\n",
    "def convert_df_ravenpro(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Converts a dataframe to the format used by RavenPro\n",
    "    \"\"\"\n",
    "\n",
    "    ravenpro_df = df.copy()\n",
    "\n",
    "    ravenpro_df.rename(columns={\n",
    "        \"start_time\": \"Begin Time (s)\",\n",
    "        \"end_time\": \"End Time (s)\",\n",
    "        \"low_freq\": \"Low Freq (Hz)\",\n",
    "        \"high_freq\": \"High Freq (Hz)\",\n",
    "        \"event\": \"Annotation\",\n",
    "    }, inplace=True)\n",
    "\n",
    "    ravenpro_df[\"Selection\"] = \"Waveform 1\"\n",
    "    ravenpro_df[\"View\"] = \"1\"\n",
    "    ravenpro_df[\"Channel\"] = \"1\"\n",
    "\n",
    "    return ravenpro_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We only have 1 model in `cfg['models]`:\n",
    "   - So we can remove the for loop and rewrite `_apply_models()` by replacing every instance of `model` with `cfg['models'][0]`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_models(cfg, segmented_file_paths):\n",
    "    csv_names = []\n",
    "    audio_file_path = cfg['audio_file']\n",
    "    process_pool = multiprocessing.Pool(cfg['num_processes'])\n",
    "\n",
    "    l_for_mapping = [{\n",
    "        'audio_seg': audio_seg, \n",
    "        'model': cfg['models'][0],\n",
    "        'original_file_name': audio_file_path,\n",
    "        } for audio_seg in segmented_file_paths]\n",
    "\n",
    "    pred_dfs = tqdm(\n",
    "        process_pool.imap(_apply_model, l_for_mapping, chunksize=1), \n",
    "        desc=f\"Applying {cfg['models'][0].get_name()}\",\n",
    "        total=len(l_for_mapping),\n",
    "    )\n",
    "\n",
    "    agg_df = gen_empty_df() \n",
    "    agg_df = pd.concat(pred_dfs, ignore_index=True)\n",
    "\n",
    "    csv_name = _generate_csv(agg_df, cfg['models'][0].get_name(),\n",
    "        audio_file_path.name,\n",
    "        cfg['output_dir'],\n",
    "        cfg['should_csv']\n",
    "    )\n",
    "    csv_names.append(csv_name)\n",
    "\n",
    "    return csv_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) We are going to run code after `segmented_file_paths` has been generated, so let's also remove the method header and return.\n",
    "\n",
    "3) We see the top portion of this code generates mappings called `l_for_mapping`\n",
    "\n",
    "4) The middle portion calls `_apply_model()` to run the model on the mappings.\n",
    "\n",
    "5) The bottom portion deals in generating a csv using the DataFrame `pred_dfs`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's break it up just like that:\n",
    "\n",
    "Let's also remove defining csv_names as there will only be 1 csv_name because of 1 model:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top portion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'audio_seg': {'audio_file': '../output/tmp/20210910_030000__0.00_30.00.wav',\n",
       "   'offset': 0.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__30.00_60.00.wav',\n",
       "   'offset': 30.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__60.00_90.00.wav',\n",
       "   'offset': 60.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__90.00_120.00.wav',\n",
       "   'offset': 90.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__120.00_150.00.wav',\n",
       "   'offset': 120.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__150.00_180.00.wav',\n",
       "   'offset': 150.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__180.00_210.00.wav',\n",
       "   'offset': 180.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__210.00_240.00.wav',\n",
       "   'offset': 210.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__240.00_270.00.wav',\n",
       "   'offset': 240.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__270.00_300.00.wav',\n",
       "   'offset': 270.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__300.00_330.00.wav',\n",
       "   'offset': 300.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__330.00_360.00.wav',\n",
       "   'offset': 330.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__360.00_390.00.wav',\n",
       "   'offset': 360.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__390.00_420.00.wav',\n",
       "   'offset': 390.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__420.00_450.00.wav',\n",
       "   'offset': 420.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__450.00_480.00.wav',\n",
       "   'offset': 450.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__480.00_510.00.wav',\n",
       "   'offset': 480.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__510.00_540.00.wav',\n",
       "   'offset': 510.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__540.00_570.00.wav',\n",
       "   'offset': 540.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__570.00_600.00.wav',\n",
       "   'offset': 570.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__600.00_630.00.wav',\n",
       "   'offset': 600.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__630.00_660.00.wav',\n",
       "   'offset': 630.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__660.00_690.00.wav',\n",
       "   'offset': 660.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__690.00_720.00.wav',\n",
       "   'offset': 690.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__720.00_750.00.wav',\n",
       "   'offset': 720.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__750.00_780.00.wav',\n",
       "   'offset': 750.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__780.00_810.00.wav',\n",
       "   'offset': 780.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__810.00_840.00.wav',\n",
       "   'offset': 810.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__840.00_870.00.wav',\n",
       "   'offset': 840.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__870.00_900.00.wav',\n",
       "   'offset': 870.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__900.00_930.00.wav',\n",
       "   'offset': 900.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__930.00_960.00.wav',\n",
       "   'offset': 930.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__960.00_990.00.wav',\n",
       "   'offset': 960.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__990.00_1020.00.wav',\n",
       "   'offset': 990.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1020.00_1050.00.wav',\n",
       "   'offset': 1020.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1050.00_1080.00.wav',\n",
       "   'offset': 1050.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1080.00_1110.00.wav',\n",
       "   'offset': 1080.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1110.00_1140.00.wav',\n",
       "   'offset': 1110.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1140.00_1170.00.wav',\n",
       "   'offset': 1140.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1170.00_1200.00.wav',\n",
       "   'offset': 1170.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1200.00_1230.00.wav',\n",
       "   'offset': 1200.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1230.00_1260.00.wav',\n",
       "   'offset': 1230.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1260.00_1290.00.wav',\n",
       "   'offset': 1260.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1290.00_1320.00.wav',\n",
       "   'offset': 1290.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1320.00_1350.00.wav',\n",
       "   'offset': 1320.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1350.00_1380.00.wav',\n",
       "   'offset': 1350.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1380.00_1410.00.wav',\n",
       "   'offset': 1380.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1410.00_1440.00.wav',\n",
       "   'offset': 1410.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1440.00_1470.00.wav',\n",
       "   'offset': 1440.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1470.00_1500.00.wav',\n",
       "   'offset': 1470.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1500.00_1530.00.wav',\n",
       "   'offset': 1500.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1530.00_1560.00.wav',\n",
       "   'offset': 1530.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1560.00_1590.00.wav',\n",
       "   'offset': 1560.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1590.00_1620.00.wav',\n",
       "   'offset': 1590.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1620.00_1650.00.wav',\n",
       "   'offset': 1620.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1650.00_1680.00.wav',\n",
       "   'offset': 1650.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1680.00_1710.00.wav',\n",
       "   'offset': 1680.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1710.00_1740.00.wav',\n",
       "   'offset': 1710.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1740.00_1770.00.wav',\n",
       "   'offset': 1740.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')},\n",
       " {'audio_seg': {'audio_file': '../output/tmp/20210910_030000__1770.00_1795.00.wav',\n",
       "   'offset': 1770.0},\n",
       "  'model': <models.bat_call_detector.model_detector.BatCallDetector at 0x28a6cb340>,\n",
       "  'original_file_name': PosixPath('/Users/adityakrishna/Documents/Research/Lab_related/20210910_030000.WAV')}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file_path = cfg['audio_file']\n",
    "process_pool = multiprocessing.Pool(cfg['num_processes'])\n",
    "\n",
    "l_for_mapping = [{\n",
    "    'audio_seg': audio_seg, \n",
    "    'model': cfg['models'][0],\n",
    "    'original_file_name': audio_file_path,\n",
    "    } for audio_seg in segmented_file_paths]\n",
    "\n",
    "l_for_mapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Middle portion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_portion():\n",
    "    pred_dfs = tqdm(\n",
    "        process_pool.imap(_apply_model, l_for_mapping, chunksize=1), \n",
    "        desc=f\"Applying {cfg['models'][0].get_name()}\",\n",
    "        total=len(l_for_mapping),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom portion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_portion(pred_dfs):\n",
    "    agg_df = gen_empty_df() \n",
    "    agg_df = pd.concat(pred_dfs, ignore_index=True)\n",
    "\n",
    "    csv_name = _generate_csv(agg_df, cfg['models'][0].get_name(),\n",
    "        audio_file_path.name,\n",
    "        cfg['output_dir'],\n",
    "        cfg['should_csv']\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To focus on the detection pipeline, let's dissect the middle portion now\n",
    "\n",
    "#### Below is the relevant code with the middle portion packaged in a method to not interfere with workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_portion():\n",
    "    pred_dfs = tqdm(\n",
    "        process_pool.imap(_apply_model, l_for_mapping, chunksize=1), \n",
    "        desc=f\"Applying {cfg['models'][0].get_name()}\",\n",
    "        total=len(l_for_mapping),\n",
    "    )\n",
    "\n",
    "def _apply_model(item):\n",
    "    annotations_df = item['model'].run(item['audio_seg']['audio_file'])\n",
    "    return pipeline._correct_annotation_offsets(\n",
    "        annotations_df,\n",
    "        item['original_file_name'],\n",
    "        item['audio_seg']['offset']\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The middle portion can be written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [08:49<00:00,  8.82s/it]\n"
     ]
    }
   ],
   "source": [
    "all_preds = pd.DataFrame()\n",
    "for i in tqdm(range(len(l_for_mapping))):\n",
    "    cur_seg = l_for_mapping[i]\n",
    "    df = _apply_model(cur_seg)\n",
    "    all_preds = pd.concat([all_preds, df])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing this, we can decide to explore `_apply_model(item)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_model(item):\n",
    "    annotations_df = item['model'].run(item['audio_seg']['audio_file'])\n",
    "    return pipeline._correct_annotation_offsets(\n",
    "        annotations_df,\n",
    "        item['original_file_name'],\n",
    "        item['audio_seg']['offset']\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To go deeper, we need to explore `item['model'].run(item['audio_seg']['audio_file'])`\n",
    "\n",
    "- `item['model']` is a `models.bat_call_detector.model_detector.BatCallDetector` object\n",
    "- `.run()` can be found in `src/models/bat_call_detector/model_detector.py`\n",
    "- `item['audio_seg]['audio_file]` is a path to an audio segment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the `.run()` method in `src/models/bat_call_detector/model_detector.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(self, audio_file):\n",
    "    \"\"\"\n",
    "    Creates a loop for feeding buzz to remove false positive.\n",
    "    Parameters::\n",
    "        bd_output: pd.DataFrame\n",
    "            DataFrame containing bat calls true positive values, result from Bat Detect pipeline.\n",
    "\n",
    "        fb_output: pd.DataFrame\n",
    "            DataFrame containing feeding buzz detections, result from Template Matching pipeline.\n",
    "            \n",
    "    Return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    bd_output = self._run_batdetect(audio_file)\n",
    "    fb_output = self._run_feedbuzz(audio_file)\n",
    "    fb_final_output = self._buzzfeed_fp_removal(bd_output, fb_output)\n",
    "\n",
    "    return pd.concat([bd_output,fb_final_output])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here:\n",
    "- `_run_batdetect(audio_file)` will provide the detections generated by batdetect2\n",
    "- `_run_feedbuzz(audio_file)` will provide the detections generated by scikit-MAAD template matching\n",
    "- Feedbuzzes are also compared against search-phase calls with `_buzzfeed_fp_removal(bd_output, fb_output)` for false negative elimination"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the middle portion referred to above, this time broken up to show each detection pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = pd.DataFrame()\n",
    "for i in tqdm(range(len(l_for_mapping))):\n",
    "    cur_seg = l_for_mapping[i]\n",
    "    bd_annotations_df = cur_seg['model']._run_batdetect(cur_seg['audio_seg']['audio_file'])\n",
    "    bd_preds = pipeline._correct_annotation_offsets(\n",
    "            bd_annotations_df,\n",
    "            cur_seg['original_file_name'],\n",
    "            cur_seg['audio_seg']['offset']\n",
    "        )\n",
    "\n",
    "    fb_annotations_df = cur_seg['model']._run_feedbuzz(cur_seg['audio_seg']['audio_file'])\n",
    "    fb_final_output = cur_seg['model']._buzzfeed_fp_removal(bd_annotations_df, fb_annotations_df)\n",
    "    fb_preds = pipeline._correct_annotation_offsets(\n",
    "            fb_final_output,\n",
    "            cur_seg['original_file_name'],\n",
    "            cur_seg['audio_seg']['offset']\n",
    "        )\n",
    "    \n",
    "    df = pd.concat([bd_preds, fb_preds])\n",
    "    all_preds = pd.concat([all_preds, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>low_freq</th>\n",
       "      <th>high_freq</th>\n",
       "      <th>detection_confidence</th>\n",
       "      <th>event</th>\n",
       "      <th>input_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161.411866</td>\n",
       "      <td>161.637555</td>\n",
       "      <td>17670.76</td>\n",
       "      <td>49011.86</td>\n",
       "      <td>0.266925</td>\n",
       "      <td>Feeding Buzz</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246.932500</td>\n",
       "      <td>246.941800</td>\n",
       "      <td>28046.00</td>\n",
       "      <td>37602.00</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>Echolocation</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>247.216500</td>\n",
       "      <td>247.226400</td>\n",
       "      <td>28046.00</td>\n",
       "      <td>38133.00</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>Echolocation</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247.352500</td>\n",
       "      <td>247.362700</td>\n",
       "      <td>28046.00</td>\n",
       "      <td>38892.00</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>Echolocation</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247.471500</td>\n",
       "      <td>247.479400</td>\n",
       "      <td>27187.00</td>\n",
       "      <td>42404.00</td>\n",
       "      <td>0.763000</td>\n",
       "      <td>Echolocation</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1781.446500</td>\n",
       "      <td>1781.456500</td>\n",
       "      <td>25468.00</td>\n",
       "      <td>32664.00</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>Echolocation</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1781.578500</td>\n",
       "      <td>1781.589100</td>\n",
       "      <td>26328.00</td>\n",
       "      <td>32298.00</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>Echolocation</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1781.938500</td>\n",
       "      <td>1781.947700</td>\n",
       "      <td>26328.00</td>\n",
       "      <td>34069.00</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>Echolocation</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1782.061500</td>\n",
       "      <td>1782.070200</td>\n",
       "      <td>25468.00</td>\n",
       "      <td>34393.00</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Echolocation</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1782.573500</td>\n",
       "      <td>1782.581900</td>\n",
       "      <td>26328.00</td>\n",
       "      <td>34609.00</td>\n",
       "      <td>0.511000</td>\n",
       "      <td>Echolocation</td>\n",
       "      <td>/Users/adityakrishna/Documents/Research/Lab_re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_time     end_time  low_freq  high_freq  detection_confidence  \\\n",
       "0    161.411866   161.637555  17670.76   49011.86              0.266925   \n",
       "0    246.932500   246.941800  28046.00   37602.00              0.549000   \n",
       "1    247.216500   247.226400  28046.00   38133.00              0.573000   \n",
       "2    247.352500   247.362700  28046.00   38892.00              0.555000   \n",
       "3    247.471500   247.479400  27187.00   42404.00              0.763000   \n",
       "..          ...          ...       ...        ...                   ...   \n",
       "49  1781.446500  1781.456500  25468.00   32664.00              0.584000   \n",
       "50  1781.578500  1781.589100  26328.00   32298.00              0.577000   \n",
       "51  1781.938500  1781.947700  26328.00   34069.00              0.614000   \n",
       "52  1782.061500  1782.070200  25468.00   34393.00              0.600000   \n",
       "53  1782.573500  1782.581900  26328.00   34609.00              0.511000   \n",
       "\n",
       "           event                                         input_file  \n",
       "0   Feeding Buzz  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "0   Echolocation  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "1   Echolocation  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "2   Echolocation  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "3   Echolocation  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "..           ...                                                ...  \n",
       "49  Echolocation  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "50  Echolocation  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "51  Echolocation  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "52  Echolocation  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "53  Echolocation  /Users/adityakrishna/Documents/Research/Lab_re...  \n",
       "\n",
       "[3263 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_batdetect(self, audio_file)-> pd.DataFrame: #\n",
    "        \"\"\"\n",
    "        Parameters:: \n",
    "            audio_file: a path containing the post-processed wav file.\n",
    "\n",
    "        Returns:: a pd.Dataframe containing the bat calls detections\n",
    "        \"\"\"\n",
    "        model, params = du.load_model(self.model_path)\n",
    "\n",
    "        # Suppress output from this call\n",
    "        text_trap = io.StringIO()\n",
    "        sys.stdout = text_trap\n",
    "\n",
    "        model_output = du.process_file(\n",
    "            audio_file=audio_file, \n",
    "            model=model, \n",
    "            params=params, \n",
    "            args= {\n",
    "                'detection_threshold': self.detection_threshold,\n",
    "                'spec_slices': self.spec_slices,\n",
    "                'chunk_size': self.chunk_size,\n",
    "                'quiet': self.quiet,\n",
    "                'spec_features' : False,\n",
    "                'cnn_features': self.cnn_features,\n",
    "            },\n",
    "            time_exp=self.time_expansion_factor,\n",
    "        )\n",
    "        # Restore stdout\n",
    "        sys.stdout = sys.__stdout__\n",
    "\n",
    "        annotations = model_output['pred_dict']['annotation']\n",
    "\n",
    "        out_df = gen_empty_df()\n",
    "        if annotations:\n",
    "            out_df = pd.DataFrame.from_records(annotations) \n",
    "            out_df['detection_confidence'] = out_df['det_prob']\n",
    "            out_df.drop(columns = ['class', 'class_prob', 'det_prob','individual'], inplace=True) # <--- These are the batdetect2 variables being dropped!\n",
    "        return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(audio_file, model, params, args, time_exp=None, top_n=5, return_raw_preds=False, max_duration=False): # <--- This method is from batdetect (not batdetect2)\n",
    "\n",
    "    # store temporary results here\n",
    "    predictions = []\n",
    "    spec_feats  = []\n",
    "    cnn_feats   = []\n",
    "    spec_slices = []\n",
    "\n",
    "    # get time expansion  factor\n",
    "    if time_exp is None:\n",
    "        time_exp = args['time_expansion_factor']\n",
    "\n",
    "    params['detection_threshold'] = args['detection_threshold']\n",
    "\n",
    "    # load audio file\n",
    "    sampling_rate, audio_full = au.load_audio_file(audio_file, time_exp,\n",
    "                                   params['target_samp_rate'], params['scale_raw_audio'])\n",
    "\n",
    "    # clipping maximum duration\n",
    "    if max_duration is not False:\n",
    "        max_duration = np.minimum(int(sampling_rate*max_duration), audio_full.shape[0])\n",
    "        audio_full = audio_full[:max_duration]\n",
    "    \n",
    "    duration_full = audio_full.shape[0] / float(sampling_rate)\n",
    "\n",
    "    return_np_spec = args['spec_features'] or args['spec_slices']\n",
    "\n",
    "    # loop through larger file and split into chunks\n",
    "    # TODO fix so that it overlaps correctly and takes care of duplicate detections at borders\n",
    "    num_chunks = int(np.ceil(duration_full/args['chunk_size']))\n",
    "    for chunk_id in range(num_chunks):\n",
    "\n",
    "        # chunk\n",
    "        chunk_time   = args['chunk_size']*chunk_id\n",
    "        chunk_length = int(sampling_rate*args['chunk_size'])\n",
    "        start_sample = chunk_id*chunk_length\n",
    "        end_sample   = np.minimum((chunk_id+1)*chunk_length, audio_full.shape[0])\n",
    "        audio = audio_full[start_sample:end_sample]\n",
    "\n",
    "        # load audio file and compute spectrogram\n",
    "        duration, spec, spec_np = du.compute_spectrogram(audio, sampling_rate, params, return_np_spec)\n",
    "\n",
    "        # evaluate model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(spec, return_feats=args['cnn_features'])\n",
    "\n",
    "        # run non-max suppression\n",
    "        pred_nms, features = pp.run_nms(outputs, params, np.array([float(sampling_rate)]))\n",
    "        pred_nms = pred_nms[0]\n",
    "        pred_nms['start_times'] += chunk_time\n",
    "        pred_nms['end_times'] += chunk_time\n",
    "\n",
    "        # if we have a background class\n",
    "        if pred_nms['class_probs'].shape[0] > len(params['class_names']):\n",
    "            pred_nms['class_probs'] = pred_nms['class_probs'][:-1, :]\n",
    "\n",
    "        predictions.append(pred_nms)\n",
    "\n",
    "        # extract features - if there are any calls detected\n",
    "        if (pred_nms['det_probs'].shape[0] > 0):\n",
    "            if args['spec_features']:\n",
    "                spec_feats.append(feats.get_feats(spec_np, pred_nms, params))\n",
    "\n",
    "            if args['cnn_features']:\n",
    "                cnn_feats.append(features[0])\n",
    "\n",
    "            if args['spec_slices']:\n",
    "                spec_slices.extend(feats.extract_spec_slices(spec_np, pred_nms, params))\n",
    "\n",
    "    # convert the predictions into output dictionary\n",
    "    file_id = os.path.basename(audio_file)\n",
    "    predictions, spec_feats, cnn_feats, spec_slices =\\\n",
    "              du.merge_results(predictions, spec_feats, cnn_feats, spec_slices)\n",
    "    results = du.convert_results(file_id, time_exp, duration_full, params,\n",
    "                              predictions, spec_feats, cnn_feats, spec_slices)\n",
    "\n",
    "    # summarize results\n",
    "    if not args['quiet']:\n",
    "        num_detections = len(results['pred_dict']['annotation'])\n",
    "        print('{}'.format(num_detections) + ' call(s) detected above the threshold.')\n",
    "\n",
    "    # print results for top n classes\n",
    "    if not args['quiet'] and (num_detections > 0):\n",
    "        class_overall = pp.overall_class_pred(predictions['det_probs'], predictions['class_probs'])\n",
    "        print('species name'.ljust(30) + 'probablity present')\n",
    "        for cc in np.argsort(class_overall)[::-1][:top_n]:\n",
    "            print(params['class_names'][cc].ljust(30) + str(round(class_overall[cc], 3)))\n",
    "\n",
    "    if return_raw_preds:\n",
    "        return predictions\n",
    "    else:\n",
    "        return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bat_msds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
